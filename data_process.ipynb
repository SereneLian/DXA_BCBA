{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv('data/DXA.csv', low_memory=False)\n",
    "new_cols = {}\n",
    "for col in data.columns:\n",
    "    new_cols[col] = col.split('first reported')[0]\n",
    "data.rename(columns= new_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map with image dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "png_df = pd.read_csv('data/png_df.csv') # path to img\n",
    "data = data.merge(png_df[['Participant ID', 'path_11','path_12']], on = ['Participant ID'], how = 'inner')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select Caucasian ethnic group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['Genetic ethnic grouping'].value_counts())\n",
    "s_data = data[data['Genetic ethnic grouping']=='Caucasian']\n",
    "len(s_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select unmatched Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_data = s_data[s_data['Sex'] == s_data['Genetic sex']]\n",
    "len(s_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the VAT and lean percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VAT:', len(s_data)- s_data['VAT (visceral adipose tissue) mass | Instance 2'].isna().sum())\n",
    "print('lean mass:',len(s_data)- s_data['Total lean mass | Instance 2'].isna().sum())\n",
    "print('total mass:',len(s_data)- s_data['Total tissue mass | Instance 2'].isna().sum())\n",
    "print('BMD:',len(s_data)- s_data['Total BMD (bone mineral density) T-score | Instance 2'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from here we have two groups of data:\n",
    "\n",
    "new_data: to get HC reference group\n",
    "\n",
    "s_data: to get hc + disease group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = s_data[['Participant ID','Date of attending assessment centre | Instance 2','Sex' ,'Age when attended assessment centre | Instance 2','VAT (visceral adipose tissue) mass | Instance 2','Total lean mass | Instance 2', 'Total tissue mass | Instance 2','Total BMD (bone mineral density) T-score | Instance 2', 'path_11','path_12']]\n",
    "new_data['VAT_Rate'] = new_data['VAT (visceral adipose tissue) mass | Instance 2']/new_data['Total tissue mass | Instance 2']*100\n",
    "new_data['lean_Rate'] = new_data['Total lean mass | Instance 2']/new_data['Total tissue mass | Instance 2']* 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self report cancers\n",
    "self_cancer =pd.read_csv('data/self_cancer.csv')\n",
    "self_cancer_remove = set(self_cancer['Participant ID'])\n",
    "print(len(new_data))\n",
    "# for HC reference group\n",
    "new_data = new_data[~new_data['Participant ID'].isin(self_cancer_remove)]\n",
    "print(len(new_data))\n",
    "# all hc and disease group\n",
    "s_data = s_data[~s_data['Participant ID'].isin(self_cancer_remove)]\n",
    "print(len(s_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_processing/label/cancer_record.pkl', 'rb') as f_read:\n",
    "    cancer_record = pickle.load(f_read)\n",
    "date_dic = {}\n",
    "for i in range(len(new_data)):\n",
    "    p = new_data.iloc[i]\n",
    "    date_dic[p['Participant ID']] = datetime.strptime(p['Date of attending assessment centre | Instance 2'], '%Y-%m-%d')\n",
    "\n",
    "official_list = []\n",
    "disase_record = []\n",
    "for k, v in cancer_record.items():\n",
    "    if k in date_dic.keys():\n",
    "    # k is id, v is the dictionary of cancer record\n",
    "        to_add = 0\n",
    "        ins_date = date_dic[k] # attchend isntance data\n",
    "        for kk, vv in v.items(): # kk is the ICD, vv is the disease date\n",
    "            if type(vv) == str:\n",
    "                di_data= datetime.strptime(vv, '%Y-%m-%d') # disease date\n",
    "                duration = (di_data - ins_date).days\n",
    "                if duration >=0: # have disease after 180 days\n",
    "                    disase_record.append([k,kk, duration])\n",
    "                else:\n",
    "                    to_add +=1\n",
    "            else:\n",
    "                to_add +=1\n",
    "        if to_add > 0:\n",
    "            official_list.append(k)\n",
    "print(len(new_data))\n",
    "new_data = new_data[~new_data['Participant ID'].isin(official_list)]\n",
    "s_data = s_data[~s_data['Participant ID'].isin(official_list)]\n",
    "\n",
    "# for both hc reference and all group\n",
    "print('HC reference group:', len(new_data))\n",
    "print('all group:',len(s_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make labeling\n",
    "T2 Diabetes: \"E11\", \"E12\"\n",
    "\n",
    "MACE: \"G45\", \"I21\", \"I22\", \"I23\", \"I24\", \"I25\", \"I63\", \"I64\"\n",
    "\n",
    "Hypertension: \tI10, I11, I12, I13, I15\n",
    "\n",
    "ASCVD:\tI71, I20-I25, I63, I65, I66, I70-I79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2D = ['Date '+i+' ' for i in [\"E11\", \"E12\"]]\n",
    "MACE = ['Date '+i+' ' for i in [\"G45\", \"I21\", \"I22\", \"I23\", \"I24\", \"I25\", \"I63\", \"I64\"]]\n",
    "Hypertension = ['Date '+i+' ' for i in [\"I10\", \"I11\", \"I12\", \"I13\", \"I15\"]]\n",
    "ASCVD = ['Date '+i+' ' for i in [\"I20\", 'I21', 'I22', 'I23', 'I24', 'I25', 'I63', 'I65', 'I70', \"I71\",'I72', \"I73\", 'I74', 'I77', 'I78','I78']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disease_finder(s_data =s_data, dil=MACE):\n",
    "    new_col = [*['Participant ID','Sex' ,'Age when attended assessment centre | Instance 2','Date of attending assessment centre | Instance 2','path_11','path_12'], *dil]\n",
    "    t2d_df =  s_data[new_col]\n",
    "    durations = []\n",
    "    labels = []\n",
    "    for i in tqdm(range(len(t2d_df))):\n",
    "        p_df = t2d_df.iloc[i]\n",
    "        p_date = datetime.strptime(p_df['Date of attending assessment centre | Instance 2'],  '%Y-%m-%d')\n",
    "        p_di_datae = list(set(t2d_df[dil].iloc[i].dropna()))\n",
    "        # for multi disease, we only use the earlist one\n",
    "        if len(p_di_datae)>1:\n",
    "            p_di_datae.sort()\n",
    "            p_di_datae = [p_di_datae[0]]\n",
    "        # after the above if, len(p_di_datae)==1 and will go to the next if\n",
    "        if len(p_di_datae)==1:\n",
    "            # print(1)\n",
    "            t_data = datetime.strptime(p_di_datae[0],  '%Y-%m-%d')\n",
    "            duration = (t_data - p_date).days\n",
    "            if duration>=0:\n",
    "                labels.append(\"After\")\n",
    "            else:\n",
    "                labels.append(\"Before\")\n",
    "        elif len(p_di_datae)==0:\n",
    "            duration = (datetime.today() -p_date).days\n",
    "            labels.append('HC')\n",
    "        durations.append(duration)\n",
    "    t2d_df['durations'] = durations\n",
    "    t2d_df['label'] = labels\n",
    "    return t2d_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2d_df = disease_finder(s_data =s_data, dil=T2D)\n",
    "t2d_eid = t2d_df[t2d_df['label']=='Before']['Participant ID']\n",
    "print(len(t2d_eid))\n",
    "t2d_eid_after = t2d_df[t2d_df['label']=='After']['Participant ID']\n",
    "print(len(t2d_eid_after))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mace_df = disease_finder(s_data =s_data, dil=MACE)\n",
    "mace_eid = mace_df[mace_df['label']=='Before']['Participant ID']\n",
    "print(len(mace_eid))\n",
    "mace_eid_after = mace_df[mace_df['label']=='After']['Participant ID']\n",
    "print(len(mace_eid_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_df = disease_finder(s_data =s_data, dil=Hypertension)\n",
    "hyper_eid = hyper_df[hyper_df['label']=='Before']['Participant ID']\n",
    "print(len(hyper_eid))\n",
    "hyper_eid_after = hyper_df[hyper_df['label']=='After']['Participant ID']\n",
    "print(len(hyper_eid_after))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascvd_df = disease_finder(s_data =s_data, dil=ASCVD)\n",
    "ascvd_eid = ascvd_df[ascvd_df['label']=='Before']['Participant ID']\n",
    "print(len(ascvd_eid))\n",
    "ascvd_eid_after = ascvd_df[ascvd_df['label']=='After']['Participant ID']\n",
    "print(len(ascvd_eid_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "illed_eid = list(set([*ascvd_eid, *t2d_eid, *hyper_eid, *mace_eid]))\n",
    "print(len(illed_eid))\n",
    "after_illed_eid = list(set([*ascvd_eid_after, *t2d_eid_after, *hyper_eid_after, *mace_eid_after]))\n",
    "print(len(after_illed_eid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ill_list = [*illed_eid, *after_illed_eid]\n",
    "print(len(all_ill_list)) \n",
    "all_ill = list(set(all_ill_list))\n",
    "print(len(all_ill)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save the disease labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2d_df.rename(columns={'label':'T2D Label', 'durations':'T2D Duration'}, inplace=True)\n",
    "hyper_df.rename(columns={'label':'Hypertension Label', 'durations':'Hypertension Duration'}, inplace=True)\n",
    "mace_df.rename(columns={'label':'MACE Label', 'durations':'MACE Duration'}, inplace=True)\n",
    "ascvd_df.rename(columns={'label':'ASCVD Label', 'durations':'ASCVD Duration'}, inplace=True)\n",
    "new_t2d = ['Participant ID','Sex' ,'Age when attended assessment centre | Instance 2','Date of attending assessment centre | Instance 2','path_11','path_12','T2D Label' ,'T2D Duration']\n",
    "new_hyp = ['Participant ID','Sex' ,'Age when attended assessment centre | Instance 2','Date of attending assessment centre | Instance 2','path_11','path_12','Hypertension Label' ,'Hypertension Duration']\n",
    "new_mace = ['Participant ID','Sex' ,'Age when attended assessment centre | Instance 2','Date of attending assessment centre | Instance 2','path_11','path_12','MACE Label' ,'MACE Duration']\n",
    "new_ascvd = ['Participant ID','Sex' ,'Age when attended assessment centre | Instance 2','Date of attending assessment centre | Instance 2','path_11','path_12','ASCVD Label' ,'ASCVD Duration']\n",
    "\n",
    "di_df = t2d_df[new_t2d].merge(hyper_df[new_hyp], on = new_t2d[:6], how='inner')\n",
    "di_df = di_df.merge(mace_df[new_mace], on = new_t2d[:6], how='inner')\n",
    "di_df = di_df.merge(ascvd_df[new_ascvd], on = new_t2d[:6], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "di_df_f = di_df[di_df.Sex=='Female']\n",
    "print(len(di_df_f))\n",
    "di_df_m = di_df[di_df.Sex=='Male']\n",
    "print(len(di_df_m))\n",
    "di_df.to_csv('data/disease_label.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select sex df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = new_data[~new_data['Participant ID'].isin(all_ill)]\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainF, validateF, testF = np.split(new_data.sample(frac=1, random_state=42), \n",
    "#                        [int(.7*len(new_data)), int(.85*len(new_data))])\n",
    "# print(len(trainF))\n",
    "# trainF.to_csv('data/All_data_train.csv', index=False)\n",
    "# validateF.to_csv('data/All_data_val.csv', index=False)\n",
    "# testF.to_csv('data/All_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_data = new_data[new_data.Sex =='Female']\n",
    "print(len(F_data))\n",
    "M_data = new_data[new_data.Sex =='Male']\n",
    "print(len(M_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_hc_patients = new_data['Participant ID'].to_list()\n",
    "new_data = new_data.dropna()\n",
    "new_data.reset_index(inplace=True)\n",
    "len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_hc_data = set(old_hc_patients)-set(new_data['Participant ID'])\n",
    "len(na_hc_data)\n",
    "na_hc = pd.DataFrame(na_hc_data, columns=['Remove'])\n",
    "na_hc.to_csv('data/na_hc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['Age_Label'] = pd.cut(x=new_data['Age when attended assessment centre | Instance 2'], \n",
    "                               bins=[40, 50, 60, 70, 80, 90], labels=['40-49', '50-59', '60-69', '70-79', '80-89']) \n",
    "new_data.groupby('Age_Label').count()/len(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_data = new_data[new_data.Sex =='Female']\n",
    "print(len(F_data))\n",
    "M_data = new_data[new_data.Sex =='Male']\n",
    "print(len(M_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = F_data[['VAT_Rate', 'lean_Rate']]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 5))\n",
    "# quantiles = ['5%', '10%','25%','50%', '75%', '90%', '95%']\n",
    "quantiles = ['mean-std','mean', 'mean+std', ]\n",
    "colors = ['green', 'red', 'blue']\n",
    "\n",
    "for col, ax in zip(plot_data, axes.flat):\n",
    "#     print(col, ax)\n",
    "    sns.histplot(ax=ax, data=plot_data, x=plot_data[col], multiple='stack')\n",
    "    m = plot_data[col].mean()\n",
    "    s = plot_data[col].std()\n",
    "    desc = [m-s, m, m+s]\n",
    "    for i in range(len(quantiles)):\n",
    "        ax.axvline(desc[i], color=colors[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hc_select(F_data): \n",
    "    # VAT_upper = F_data['VAT_Rate'].quantile(.25)\n",
    "    # VAT_lower = F_data['VAT_Rate'].quantile(.75)\n",
    "    VAT_upper = F_data['VAT_Rate'].mean() - F_data['VAT_Rate'].std()\n",
    "    VAT_lower = F_data['VAT_Rate'].mean() + F_data['VAT_Rate'].std()\n",
    "    print(VAT_upper, VAT_lower)\n",
    "    lean_upper = F_data['lean_Rate'].mean() - F_data['lean_Rate'].std()\n",
    "    lean_lower = F_data['lean_Rate'].mean() + F_data['lean_Rate'].std()\n",
    "    print(lean_upper, lean_lower)\n",
    "    # lean_upper = F_data['lean_Rate'].quantile(.25)\n",
    "    # lean_lower = F_data['lean_Rate'].quantile(.75)\n",
    "    F_new_data = F_data\n",
    "    F_new_data = F_new_data[F_new_data.VAT_Rate <=VAT_lower]\n",
    "    F_new_data = F_new_data[F_new_data.VAT_Rate >=VAT_upper]\n",
    "    F_new_data = F_new_data[F_new_data.lean_Rate <=lean_lower]\n",
    "    F_new_data = F_new_data[F_new_data.lean_Rate >=lean_upper]\n",
    "    return F_new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_new_data = hc_select(F_data)\n",
    "print(len(F_new_data))\n",
    "M_new_data = hc_select(M_data)\n",
    "print(len(M_new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_data_group = F_data.groupby('Age_Label')\n",
    "# print(F_data_group.count())\n",
    "F_new_data = pd.concat([hc_select(group) for name, group in F_data_group])\n",
    "print(len(F_new_data))\n",
    "# Group the dataframe by age group\n",
    "M_data_group = M_data.groupby('Age_Label')\n",
    "M_new_data = pd.concat([hc_select(group) for name, group in M_data_group])\n",
    "print(len(M_new_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainF, validateF, testF = np.split(F_data.sample(frac=1, random_state=42), \n",
    "#                        [int(.7*len(F_data)), int(.8*len(F_data))])\n",
    "# print(len(validateF))\n",
    "# trainF.to_csv('data/F_data_train.csv', index=False)\n",
    "# validateF.to_csv('data/F_data_val.csv', index=False)\n",
    "# testF.to_csv('data/F_data_test.csv', index=False)\n",
    "# trainM, validateM, testM = np.split(M_data.sample(frac=1, random_state=42), \n",
    "#                        [int(.7*len(M_data)), int(.8*len(M_data))])\n",
    "# print(len(trainM))\n",
    "# trainM.to_csv('data/M_data_train.csv', index=False)\n",
    "# validateM.to_csv('data/M_data_val.csv', index=False)\n",
    "# testM.to_csv('data/M_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainF, validateF, testF = np.split(F_new_data.sample(frac=1, random_state=42), \n",
    "                       [int(.7*len(F_new_data)), int(.8*len(F_new_data))])\n",
    "print(len(trainF))\n",
    "trainF.to_csv('data/F_na_data_train.csv', index=False)\n",
    "validateF.to_csv('data/F_na_data_val.csv', index=False)\n",
    "testF.to_csv('data/F_na_data_test.csv', index=False)\n",
    "trainM, validateM, testM = np.split(M_new_data.sample(frac=1, random_state=42), \n",
    "                       [int(.7*len(M_new_data)), int(.8*len(M_new_data))])\n",
    "print(len(trainM))\n",
    "trainM.to_csv('data/M_na_data_train.csv', index=False)\n",
    "validateM.to_csv('data/M_na_data_val.csv', index=False)\n",
    "testM.to_csv('data/M_na_data_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_f = pd.read_csv('data/F_na_data_train.csv')\n",
    "train_m = pd.read_csv('data/M_na_data_train.csv')\n",
    "val_f = pd.read_csv('data/F_na_data_val.csv')\n",
    "val_m = pd.read_csv('data/M_na_data_val.csv')\n",
    "test_f = pd.read_csv('data/F_na_data_test.csv')\n",
    "test_m = pd.read_csv('data/M_na_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train_f, train_m], ignore_index=False)\n",
    "train.sample(frac=1, replace=True, ignore_index=True, random_state=42)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = pd.concat([val_f, val_m], ignore_index=False)\n",
    "val.sample(frac=1, replace=True, ignore_index=True, random_state=42)\n",
    "val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([test_f, test_m], ignore_index=False)\n",
    "test.sample(frac=1, replace=True, ignore_index=True, random_state=42)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('data/train.csv', index=False)\n",
    "val.to_csv('data/val.csv', index=False)\n",
    "test.to_csv('data/test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
