{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import set_config\n",
    "from sksurv.linear_model import CoxPHSurvivalAnalysis, CoxnetSurvivalAnalysis\n",
    "from sksurv.metrics import concordance_index_censored\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_f = pd.read_csv('results/center_female.csv')\n",
    "label_m = pd.read_csv('results/center_male.csv')\n",
    "label_f['BA-CA'] = label_f['BA'] - label_f['CA']\n",
    "label_m['BA-CA'] = label_m['BA'] - label_m['CA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hazaard_calculator(t2df, target, within= False):\n",
    "   llabel = target+' '+'Label'\n",
    "   # t2df = t2df[~t2df['VAT_label'].isin(['Pre-existing Disease','Post-DXA and Pre-Disease'])] # remove previous disease\n",
    "   t2df = t2df[~t2df[llabel].isin(['Before'])] # remove previous disease\n",
    "   # t2df= t2df[~t2df['VAT_label'].isin(['Normal', 'Hypernormal'])]\n",
    "   if within:\n",
    "      t2df = t2df[t2df[target+' '+'Duration']<= 365*within]\n",
    "   print(t2df[llabel].value_counts())\n",
    "   t2df['Status'] = t2df[llabel].apply(lambda x: True if x == 'After' else False)\n",
    "   t2df['Survival_in_days'] = t2df[target+' '+'Duration']\n",
    "   # # Create Model'\n",
    "   # t2df['Sex_enbed'] = t2df['Sex'].apply(lambda x: 0 if x == 'Female' else 1)\n",
    "   t2df = t2df[['CA',  'BA','BA-CA','VAT_Rate', 'lean_Rate','Diastolic blood pressure', 'BMI','Waist circumference',\n",
    "       'Systolic blood pressure', 'Antihypertension','Hip circumference', 'Smoking','Status', 'Survival_in_days']]\n",
    "   x = t2df.fillna(t2df.mean())\n",
    "   # x = t2df.dropna()\n",
    "   # print(\"Remove NA:\", len(t2df)-len(x))\n",
    "   x = OneHotEncoder().fit_transform(x)\n",
    "   print(x['Status'].value_counts())\n",
    "   iy = ['Status', 'Survival_in_days']\n",
    "   kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "   c_test_t = []\n",
    "   c_test_v = []\n",
    "   c_test_b = []\n",
    "   for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "      print('Fold:', i)\n",
    "      train = x.iloc[train_index]\n",
    "      test = x.iloc[test_index]\n",
    "      # print('CA')\n",
    "      cph1 = CoxnetSurvivalAnalysis(l1_ratio=0.99, fit_baseline_model=True)\n",
    "      int1 = ['CA', 'BMI', 'Diastolic blood pressure', 'Systolic blood pressure', 'Smoking', 'Waist circumference', 'Hip circumference']\n",
    "      cph1.fit(train[int1], train[iy].to_records(index=False))\n",
    "      # print(cph1)\n",
    "      # print('BA')\n",
    "      # int2 = ['CA', 'VAT_Rate', 'lean_Rate']\n",
    "      int2 = ['VAT_Rate', 'lean_Rate', 'BMI', 'Diastolic blood pressure', 'Systolic blood pressure', 'Smoking', 'Waist circumference', 'Hip circumference']\n",
    "      cph2 = CoxnetSurvivalAnalysis(l1_ratio=0.99, fit_baseline_model=True)\n",
    "      cph2.fit(train[int2], train[iy].to_records(index=False))\n",
    "      # int3 = ['BA', 'CA']\n",
    "      int3 = ['BA', 'BMI', 'Diastolic blood pressure', 'Systolic blood pressure', 'Smoking', 'Waist circumference', 'Hip circumference']\n",
    "   #    cph2 = CoxPHFitter()\n",
    "      cph3 = CoxnetSurvivalAnalysis(l1_ratio=0.99, fit_baseline_model=True)\n",
    "      cph3.fit(train[int3], train[iy].to_records(index=False))\n",
    "      # print('Traditional C-Index')\n",
    "      train_tradition = concordance_index_censored(train[\"Status\"], train[\"Survival_in_days\"], cph1.predict(train[int1]))\n",
    "      # print(train_tradition)\n",
    "      test_tradition = concordance_index_censored(test[\"Status\"], test[\"Survival_in_days\"], cph1.predict(test[int1]))\n",
    "      train_vt = concordance_index_censored(train[\"Status\"], train[\"Survival_in_days\"], cph2.predict(train[int2]))\n",
    "      test_vt = concordance_index_censored(test[\"Status\"], test[\"Survival_in_days\"], cph2.predict(test[int2]))\n",
    "      train_ba = concordance_index_censored(train[\"Status\"], train[\"Survival_in_days\"], cph3.predict(train[int3]))\n",
    "      test_ba = concordance_index_censored(test[\"Status\"], test[\"Survival_in_days\"], cph3.predict(test[int3]))\n",
    "      # print(test_ba)\n",
    "      c_test_t.append(test_tradition[0])\n",
    "      c_test_v.append(test_vt[0])\n",
    "      c_test_b.append(test_ba[0])\n",
    "   print(np.mean(c_test_t) ,st.t.interval(alpha=0.95, df=len(c_test_t)-1, \n",
    "              loc=np.mean(c_test_t), \n",
    "              scale=st.sem(c_test_t)) )\n",
    "   print(np.mean(c_test_v), st.t.interval(alpha=0.95, df=len(c_test_v)-1, \n",
    "              loc=np.mean(c_test_v), \n",
    "              scale=st.sem(c_test_v)))\n",
    "   print(np.mean(c_test_b), st.t.interval(alpha=0.95, df=len(c_test_b)-1, \n",
    "              loc=np.mean(c_test_b), \n",
    "              scale=st.sem(c_test_b)))\n",
    "   \n",
    "   print(st.ttest_ind(c_test_t, c_test_b))\n",
    "   print(st.ttest_ind(c_test_t, c_test_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([label_m, label_f],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hazaard_calculator_all(t2df, target, within= False, n_splits=10):\n",
    "   llabel = target+' '+'Label'\n",
    "   t2df = t2df[~t2df[llabel].isin(['Before'])] # remove previous disease\n",
    "   t2df= t2df[~t2df['VAT_label'].isin(['Normal', 'Hypernormal'])]\n",
    "   if within:\n",
    "      t2df = t2df[t2df[target+' '+'Duration']<= 365*within]\n",
    "   print(t2df[llabel].value_counts())\n",
    "   t2df['Status'] = t2df[llabel].apply(lambda x: True if x == 'After' else False)\n",
    "   t2df['Survival_in_days'] = t2df[target+' '+'Duration']\n",
    "   # # Create Model'\n",
    "   t2df['Sex_enbed'] = t2df['Sex'].apply(lambda x: 0 if x == 'Female' else 1)\n",
    "   t2df = t2df[['CA', 'Sex_enbed', 'BA','BA-CA','VAT_Rate', 'lean_Rate','Diastolic blood pressure', 'BMI','Waist circumference',\n",
    "       'Systolic blood pressure', 'Antihypertension','Hip circumference', 'Smoking','Status', 'Survival_in_days']]\n",
    "   x = t2df.fillna(t2df.mean())\n",
    "   x = OneHotEncoder().fit_transform(x)\n",
    "   print(x['Status'].value_counts())\n",
    "   iy = ['Status', 'Survival_in_days']\n",
    "   kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "   c_test_t = []\n",
    "   c_test_v = []\n",
    "   c_test_b = []\n",
    "   for i, (train_index, test_index) in enumerate(kf.split(x)):\n",
    "      print('Fold:', i)\n",
    "      train = x.iloc[train_index]\n",
    "      test = x.iloc[test_index]\n",
    "      # print('CA')\n",
    "      cph1 = CoxnetSurvivalAnalysis(l1_ratio=0.99, fit_baseline_model=True)\n",
    "      int1 = ['CA','Sex_enbed', 'BMI', 'Diastolic blood pressure', 'Systolic blood pressure', 'Smoking', 'Waist circumference', 'Hip circumference']\n",
    "      cph1.fit(train[int1], train[iy].to_records(index=False))\n",
    "      # print(cph1)\n",
    "      # print('BA')\n",
    "      int2 = ['CA', 'VAT_Rate', 'lean_Rate', 'Sex_enbed']\n",
    "      # int2 = ['VAT_Rate', 'lean_Rate','Sex_enbed', 'BMI', 'Diastolic blood pressure', 'Systolic blood pressure', 'Smoking', 'Waist circumference', 'Hip circumference']\n",
    "      cph2 = CoxnetSurvivalAnalysis(l1_ratio=0.99, fit_baseline_model=True)\n",
    "      cph2.fit(train[int2], train[iy].to_records(index=False))\n",
    "      int3 = ['BA', 'BA-CA', 'CA', 'Sex_enbed']\n",
    "      # int3 = ['BA', 'BMI','Sex_enbed', 'Diastolic blood pressure', 'Systolic blood pressure', 'Smoking', 'Waist circumference', 'Hip circumference']\n",
    "   #    cph2 = CoxPHFitter()\n",
    "      cph3 = CoxnetSurvivalAnalysis(l1_ratio=0.95, fit_baseline_model=True)\n",
    "      cph3.fit(train[int3], train[iy].to_records(index=False))\n",
    "      # print('Traditional C-Index')\n",
    "      train_tradition = concordance_index_censored(train[\"Status\"], train[\"Survival_in_days\"], cph1.predict(train[int1]))\n",
    "      # print(train_tradition)\n",
    "      test_tradition = concordance_index_censored(test[\"Status\"], test[\"Survival_in_days\"], cph1.predict(test[int1]))\n",
    "      train_vt = concordance_index_censored(train[\"Status\"], train[\"Survival_in_days\"], cph2.predict(train[int2]))\n",
    "      test_vt = concordance_index_censored(test[\"Status\"], test[\"Survival_in_days\"], cph2.predict(test[int2]))\n",
    "      train_ba = concordance_index_censored(train[\"Status\"], train[\"Survival_in_days\"], cph3.predict(train[int3]))\n",
    "      test_ba = concordance_index_censored(test[\"Status\"], test[\"Survival_in_days\"], cph3.predict(test[int3]))\n",
    "      # print(test_ba)\n",
    "      c_test_t.append(test_tradition[0])\n",
    "      c_test_v.append(test_vt[0])\n",
    "      c_test_b.append(test_ba[0])\n",
    "   print(np.mean(c_test_t) ,st.t.interval(alpha=0.95, df=len(c_test_t)-1, \n",
    "              loc=np.mean(c_test_t), \n",
    "              scale=st.sem(c_test_t)) )\n",
    "   print(np.mean(c_test_v), st.t.interval(alpha=0.95, df=len(c_test_v)-1, \n",
    "              loc=np.mean(c_test_v), \n",
    "              scale=st.sem(c_test_v)))\n",
    "   print(np.mean(c_test_b), st.t.interval(alpha=0.95, df=len(c_test_b)-1, \n",
    "              loc=np.mean(c_test_b), \n",
    "              scale=st.sem(c_test_b)))\n",
    "   \n",
    "   print(st.ttest_ind(c_test_t, c_test_b))\n",
    "   print(st.ttest_ind(c_test_t, c_test_v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hazaard_calculator_all(all_df, 'ASCVD')\n",
    "hazaard_calculator_all(all_df, 'MACE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hazaard_calculator(label_m,'ASCVD')\n",
    "hazaard_calculator(label_m,'MACE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hazaard_calculator(label_f,'MACE')\n",
    "hazaard_calculator(label_f,'ASCVD')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlung",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
